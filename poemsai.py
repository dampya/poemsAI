# -*- coding: utf-8 -*-
"""poemsAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/dampya/e61ba5270c2d4d05d7fca272a67cdb10/group_q_sourcecode.ipynb

# BiLSTM Implementation for Poem Emotion Analysis
- Ideally to be run in Google Colab
"""

!pip install nltk datasets textblob tensorflow keras

"""## Dataset preprocessing
- Dataset taken from [here](https://huggingface.co/datasets/Ozziey/poems_dataset)
"""

import pandas as pd
from datasets import load_dataset

dataset = load_dataset("Ozziey/poems_dataset", download_mode="force_redownload")

df = pd.DataFrame(dataset['train'])

"""---

## Stop-Word Removal

In natural language processing, stop words are common words that are often removed from text data because they are considered to carry little meaningful information for tasks like text classification. Common stop words include articles, pronouns, prepositions, conjunctions, auxiliary verbs, and adverbs. However, in the context of analyzing historical text, such as Shakespearean poems, there are additional stop words that need to be considered.

### Common Stop Words (Examples):

- Articles: 'a', 'an', 'the'
- Pronouns: 'I', 'you', 'he', 'she', 'it', 'we', 'they'
- Prepositions: 'in', 'at', 'on', 'over', 'under', 'with'
- Conjunctions: 'and', 'but', 'or', 'so', 'yet'
- Auxiliary Verbs: 'is', 'am', 'are', 'was', 'were', 'be', 'being', 'been'
- Common Adverbs: 'very', 'too', 'just', 'also', 'then', 'there'
- Others: 'that', 'what', 'which', 'who', 'whom'

### Additional Shakespearean Stop-Words:

There are certain unusual terms and expressions in Shakespearean English that are not common in contemporary English. Even while these terms had significance in the past, they might not be applicable to tasks involving text classification today. Shakespearean English-specific stop words include the following ones:

- **Common Articles and Prepositions:**
  - 'thee' (you)
  - 'thou' (you)
  - 'thy' (your)
  - 'thine' (yours)
  - 'ye' (you)

- **Pronouns:**
  - 'thou' (you)
  - 'thee' (you)
  - 'thy' (your)
  - 'thine' (yours)
  - 'ye' (you)

- **Auxiliary and Modal Verbs:**
  - 'hast' (have)
  - 'hath' (has)
  - 'dost' (do)
  - 'doth' (does)
  - 'wilt' (will)
  - 'shalt' (shall)

- **Conjunctions and Adverbs:**
  - 'ere' (before)
  - 'whence' (from where)
  - 'whither' (to where)
  - 'wherefore' (why)

- **Common Shakespearean Phrases:**
  - 'good morrow' (good morning)
  - 'prithee' (please)
  - 'perchance' (perhaps)
  - 'verily' (truly)

### Defining the Preprocessing Function
To handle certain Shakespearean stop-words, a data preparation tool has been built. This tool can do the following tasks:

1. Standardising letter case guarantees consistency in word processing.

2. Eliminating stop words: It gets rid of both common and unusual Shakespearean stop words.

3. material segmentation: To enable more in-depth examination, the material is divided into discrete words.

Text data is cleaned and prepared using this preprocessing tool for a variety of analytical and text classification applications.
"""

import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from imblearn.over_sampling import RandomOverSampler
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')

# define a function to calculate max lengths
def calculate_max_lengths(dataset):
    tokenizer = Tokenizer()
    tokenizer.fit_on_texts(dataset['poem content'])
    max_sequence_length = max(len(seq) for seq in tokenizer.texts_to_sequences(dataset['poem content']))
    max_words = len(tokenizer.word_index)
    return max_sequence_length, max_words

# dalculate max lengths
max_sequence_length, max_words = calculate_max_lengths(df)

# initialize and fit the tokenizer
tokenizer = Tokenizer(num_words=max_words, oov_token="<OOV>")
tokenizer.fit_on_texts(df['poem content'])

# convert text to sequences and apply padding
sequences = tokenizer.texts_to_sequences(df['poem content'])
sequences_padded = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')

def remove_stopwords(text):
    stop_words = set(stopwords.words('english'))
    additional_stopwords = ['thou', 'thy', 'thine', 'ye', 'art', 'hast', 'hath', 'dost', 'doth', 'wilt', 'shalt', 'ere', 'whence', 'whither', 'wherefore', 'good', 'morrow', 'prithee', 'perchance', 'verily']
    stop_words.update(additional_stopwords)
    return ' '.join(word for word in text.split() if word.lower() not in stop_words)

df['poem content'] = df['poem content'].apply(remove_stopwords)

# convert emotion scores to categorical labels
emotion_threshold = 0.5
emotion_classes = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']
df[emotion_classes] = (df[emotion_classes] >= emotion_threshold).astype(int)

# split the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(sequences_padded, df[emotion_classes].values, test_size=0.2, random_state=42, stratify=df[emotion_classes].values)

# apply RandomOverSampler
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X_train, y_train)

"""### Data Distribution:
- Now we verify the distribution of the `pred` values after the split to ensure that the there is an equal ratio of `pred` values across the training and testing sets.

"""

import matplotlib.pyplot as plt

train_class_counts = y_train.sum(axis=0)
test_class_counts = y_test.sum(axis=0)

emotion_classes = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']

fig, ax = plt.subplots(figsize=(10, 6))
bar_width = 0.35
index = range(len(emotion_classes))

bar1 = ax.bar(index, train_class_counts, bar_width, label='Training Set')
bar2 = ax.bar([i + bar_width for i in index], test_class_counts, bar_width, label='Testing Set')

ax.set_xlabel('Emotion Classes')
ax.set_ylabel('Counts')
ax.set_title('Distribution of Classes in Training and Testing Sets')
ax.set_xticks([i + bar_width / 2 for i in index])
ax.set_xticklabels(emotion_classes)
ax.legend()

plt.tight_layout()
plt.show()

"""C-BiLSTM Model with an embedding layer"""

from keras.models import Sequential
from keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, Conv1D, MaxPooling1D
from keras.optimizers import Adam
from keras.regularizers import L1L2
from sklearn.utils.class_weight import compute_class_weight
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.metrics import Precision, Recall
from tensorflow.keras import backend as K

precision_metric = Precision()
recall_metric = Recall()

def F1Score(y_true, y_pred):
    p = precision_metric(y_true, y_pred)
    r = recall_metric(y_true, y_pred)
    return 2 * ((p * r) / (p + r + K.epsilon()))

class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(df[emotion_classes].values.argmax(axis=1)),
    y=df[emotion_classes].values.argmax(axis=1)
)
class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}

# model configuration
embedding_dim = 50
lstm_units = 64
dropout_rate = 0.5
num_filters = 32
kernel_size = 3
pool_size = 2
regularizer = L1L2(l1=1e-5, l2=1e-4)

# build the model
model = Sequential([
    Embedding(input_dim=max_words + 1, output_dim=embedding_dim, input_length=max_sequence_length),
    Conv1D(num_filters, kernel_size, activation='relu'),
    MaxPooling1D(pool_size=pool_size),
    Bidirectional(LSTM(lstm_units, return_sequences=True, kernel_regularizer=regularizer)),
    Dropout(dropout_rate),
    Bidirectional(LSTM(lstm_units, kernel_regularizer=regularizer)),
    Dense(len(emotion_classes), activation='sigmoid', kernel_regularizer=regularizer)
])

model.compile(
    loss='categorical_crossentropy',
    optimizer=Adam(learning_rate=0.001),
    metrics=['accuracy', precision_metric, recall_metric, F1Score]
)

# define callbacks
early_stopping = EarlyStopping(monitor='val_accuracy', patience=3)
model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy')
reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, min_lr=0.001)

# fit the model
history = model.fit(
    X_resampled, y_resampled,
    epochs=30,
    batch_size=32,
    validation_data=(X_test, y_test),
    class_weight=class_weight_dict,
    callbacks=[early_stopping, model_checkpoint, reduce_lr]
)

scores = model.evaluate(X_test, y_test, verbose=0)
print(f'Test loss: {scores[0]}, Test accuracy: {scores[1]*100}%')

"""- Generate metrics on learning process and its visualisations for training and validation accuracy, loss, and F1 Score.

"""

import matplotlib.pyplot as plt

# plot training & validation accuracy
plt.figure(figsize=(12, 6))
plt.subplot(121)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='upper left')

# plot training & validation loss
plt.subplot(122)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper left')

# show plots
plt.tight_layout()
plt.show()

# plot F1 score, precision, and recall
plt.figure(figsize=(12, 6))
plt.subplot(121)
plt.plot(history.history['F1Score'], label='F1 Score')
plt.plot(history.history['val_F1Score'], label='Validation F1 Score')
plt.title('F1 Score')
plt.xlabel('Epoch')
plt.ylabel('F1 Score')
plt.legend(loc='upper left')

# show plots
plt.tight_layout()
plt.show()